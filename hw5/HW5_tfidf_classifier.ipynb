{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HW 5 - TF-IDF Classifier\n",
    "\n",
    "Goal is to make classifier which would be able to identify \"toxic\" comments [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
    "\n",
    "Data would be taken fom here - https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from yaspin import yaspin\n",
    "from yaspin.spinners import Spinners\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "# ignore matplotlib warnings for unable to represent some characters in page names\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# load data\n",
    "train = pd.read_csv('data/train.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Standard approaches for text analyzing is [Bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model), and it's modification [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).\n",
    "\n",
    "They implemented in `sklearn` as [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) and [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "More details are available by the [link](https://github.com/udsclub/workshop/blob/master/notebooks/UDS-workshop-feature-extraction-and-engineering.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_text = train['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trying basic Count Vectorizer to have a look on a data, check most frequent words, etc. \n",
    "word_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Fitting \n",
      "✅  Transforming \n",
      "                                 \n",
      "Most frequent word is: `the`, it appears 496796 times\n",
      "There are 100140 words that appears only once in dataset\n",
      "Total number of features (words): 189775\n"
     ]
    }
   ],
   "source": [
    "with yaspin(Spinners.clock, text='Fitting') as spinner:\n",
    "    word_vectorizer.fit(train_text)\n",
    "    spinner.ok('✅ ')\n",
    "    \n",
    "with yaspin(Spinners.clock, text='Transforming') as spinner:\n",
    "    train_word_features = word_vectorizer.transform(train_text)\n",
    "    spinner.ok('✅ ')\n",
    "\n",
    "# finding most frequent words\n",
    "with yaspin(Spinners.clock, text='Calculating sum for each word') as spinner:\n",
    "    sum_words = train_word_features.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in word_vectorizer.vocabulary_.items()]\n",
    "\n",
    "    most_freq_word = None\n",
    "    frequency = float('-inf')\n",
    "    less_than_N = 0\n",
    "    one_rep = 0\n",
    "    for word, freq in words_freq:\n",
    "        if freq == 1:\n",
    "            one_rep += 1\n",
    "        elif freq < 4:\n",
    "            less_than_N += 1\n",
    "        if freq > frequency:\n",
    "            frequency = freq \n",
    "            most_freq_word = word\n",
    "\n",
    "print(f'\\nMost frequent word is: `{most_freq_word}`, it appears {frequency} times')\n",
    "print(f'There are {one_rep} words that appears only once in dataset')\n",
    "print(f'Total number of features (words): {len(word_vectorizer.vocabulary_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lets try to modify our CountVectorizer for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Fitting \n",
      "✅  Transforming \n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = CountVectorizer(\n",
    "    stop_words='english',  # standard words like `the`, `and`, etc.\n",
    "    min_df=2,              # word (or n gram) should appear at least 2 times to be taken into account\n",
    "    binary=True,           # binary features\n",
    "    ngram_range=(1, 2),    # also consider two words phrases \n",
    "    lowercase=True,        # lowercase everything\n",
    ")\n",
    "\n",
    "with yaspin(Spinners.clock, text='Fitting') as spinner:\n",
    "    word_vectorizer.fit(train_text)\n",
    "    spinner.ok('✅ ')\n",
    "    \n",
    "with yaspin(Spinners.clock, text='Transforming') as spinner:\n",
    "    train_word_features = word_vectorizer.transform(train_text)\n",
    "    spinner.ok('✅ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now most frequent word is: `article`, it appears 32112 times\n",
      "There are 0 words that appears only once in dataset\n",
      "There are 420966 words that appears less than 5 times in dataset\n",
      "Total number of features (words and n-grams): 553961\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "# finding most frequent word\n",
    "# check if min_df is working (remove rarely used words)\n",
    "with yaspin(Spinners.clock, text='Calculating sum for each word') as spinner:\n",
    "    sum_words = train_word_features.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in word_vectorizer.vocabulary_.items()]\n",
    "\n",
    "    most_freq_word = None\n",
    "    frequency = float('-inf')\n",
    "    less_than_N = 0\n",
    "    one_rep = 0\n",
    "    for word, freq in words_freq:\n",
    "        if freq == 1:\n",
    "            one_rep += 1\n",
    "        elif freq < n:\n",
    "            less_than_N += 1\n",
    "        if freq > frequency:\n",
    "            frequency = freq \n",
    "            most_freq_word = word\n",
    "\n",
    "print(f'Now most frequent word is: `{most_freq_word}`, it appears {frequency} times')\n",
    "print(f'There are {one_rep} words that appears only once in dataset')\n",
    "print(f'There are {less_than_N} words that appears less than {n} times in dataset')\n",
    "print(f'Total number of features (words and n-grams): {len(word_vectorizer.vocabulary_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For classification we would be using [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(\n",
    "    penalty='l2',    # default reaularization\n",
    "    C=0.1,           # inverse of regularization strength\n",
    "    solver='lbfgs',  # default solver\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's train one classifier for each class\n",
    "\n",
    "For validation we would use [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.958886 Training toxic\n",
      "CV score for class severe_toxic is 0.975209 Training severe_toxic\n",
      "CV score for class obscene is 0.977403 Training obscene\n",
      "CV score for class threat is 0.976598 Training threat\n",
      "CV score for class insult is 0.967526 Training insult\n",
      "CV score for class identity_hate is 0.964972 Training identity_hate\n",
      "\n",
      "Total score is 0.970099\n"
     ]
    }
   ],
   "source": [
    "scores= []\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "\n",
    "    with yaspin(Spinners.clock, text=f'Training {class_name}') as spinner:\n",
    "        cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, scoring='roc_auc'))\n",
    "        spinner.ok(f'CV score for class {class_name} is {cv_score:.6f}')\n",
    "    \n",
    "    scores.append(cv_score)\n",
    "\n",
    "print(f'\\nTotal score is {np.mean(scores):.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
